{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhimsXRgj3k0"
   },
   "source": [
    "# Classification 3. Hierarchical-Separate Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T21:39:45.200616Z",
     "iopub.status.busy": "2023-03-21T21:39:45.199967Z",
     "iopub.status.idle": "2023-03-21T21:39:55.840449Z",
     "shell.execute_reply": "2023-03-21T21:39:55.837963Z",
     "shell.execute_reply.started": "2023-03-21T21:39:45.200578Z"
    },
    "id": "8d4T2gADhW7C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gI9VWEW4l19T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CfoVpFBij25G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"beer_df_large.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QSQWiK1pk8ck",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Name', 'Company', 'Region', 'ABV', 'Avg', 'Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "h4s8QJSJklIX",
    "outputId": "4d25c7c8-4505-4881-b2d1-11fb401c43c9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Style</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bocks</td>\n",
       "      <td>Bock</td>\n",
       "      <td>From a 12oz bottle into a cocktail glass.\\n\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bocks</td>\n",
       "      <td>Bock</td>\n",
       "      <td>Great relaxing beer. Very mellow, great taste-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bocks</td>\n",
       "      <td>Bock</td>\n",
       "      <td>Appearance: Clear, bright copper color. Frothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bocks</td>\n",
       "      <td>Bock</td>\n",
       "      <td>As a German staying for holidays in the US I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bocks</td>\n",
       "      <td>Bock</td>\n",
       "      <td>I would guess this is Shiner's #1 beer. It's p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174679</th>\n",
       "      <td>Wild/Sour Beers</td>\n",
       "      <td>Wild Ale</td>\n",
       "      <td>A really well done, well balanced sour with an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174680</th>\n",
       "      <td>Wild/Sour Beers</td>\n",
       "      <td>Wild Ale</td>\n",
       "      <td>22oz bottle. Poured out a slightly hazy, brigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174681</th>\n",
       "      <td>Wild/Sour Beers</td>\n",
       "      <td>Wild Ale</td>\n",
       "      <td>There's lots of apricot in this beer, just a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174682</th>\n",
       "      <td>Wild/Sour Beers</td>\n",
       "      <td>Wild Ale</td>\n",
       "      <td>Poured from a 22oz bomber into my Drie de Font...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174683</th>\n",
       "      <td>Wild/Sour Beers</td>\n",
       "      <td>Wild Ale</td>\n",
       "      <td>Got this on sale at HEB for $7. Pretty good de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174684 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Group     Style  \\\n",
       "0                 Bocks      Bock   \n",
       "1                 Bocks      Bock   \n",
       "2                 Bocks      Bock   \n",
       "3                 Bocks      Bock   \n",
       "4                 Bocks      Bock   \n",
       "...                 ...       ...   \n",
       "174679  Wild/Sour Beers  Wild Ale   \n",
       "174680  Wild/Sour Beers  Wild Ale   \n",
       "174681  Wild/Sour Beers  Wild Ale   \n",
       "174682  Wild/Sour Beers  Wild Ale   \n",
       "174683  Wild/Sour Beers  Wild Ale   \n",
       "\n",
       "                                                   Review  \n",
       "0       From a 12oz bottle into a cocktail glass.\\n\\nC...  \n",
       "1       Great relaxing beer. Very mellow, great taste-...  \n",
       "2       Appearance: Clear, bright copper color. Frothy...  \n",
       "3       As a German staying for holidays in the US I c...  \n",
       "4       I would guess this is Shiner's #1 beer. It's p...  \n",
       "...                                                   ...  \n",
       "174679  A really well done, well balanced sour with an...  \n",
       "174680  22oz bottle. Poured out a slightly hazy, brigh...  \n",
       "174681  There's lots of apricot in this beer, just a t...  \n",
       "174682  Poured from a 22oz bomber into my Drie de Font...  \n",
       "174683  Got this on sale at HEB for $7. Pretty good de...  \n",
       "\n",
       "[174684 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pale Lagers',\n",
       " 'Pale Ales',\n",
       " 'Strong Ales',\n",
       " 'Stouts',\n",
       " 'India Pale Ales',\n",
       " 'Wild/Sour Beers',\n",
       " 'Specialty Beers',\n",
       " 'Dark Lagers',\n",
       " 'Porters',\n",
       " 'Wheat Beers',\n",
       " 'Brown Ales',\n",
       " 'Bocks',\n",
       " 'Dark Ales']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = df['Group'].value_counts().index.tolist()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_dfs = []\n",
    "for g in groups:\n",
    "    new_df = df[df['Group'] == g]\n",
    "    new_df = new_df.drop('Group', axis=1)\n",
    "    group_dfs.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Style</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66877</th>\n",
       "      <td>American Adjunct Lager</td>\n",
       "      <td>Sweet, clean, green apples, mild bitterness. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66878</th>\n",
       "      <td>American Adjunct Lager</td>\n",
       "      <td>Look...Clear pale yellow with a white carbonat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66879</th>\n",
       "      <td>American Adjunct Lager</td>\n",
       "      <td>Look: Crystal clear yellow with an awesome-loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66880</th>\n",
       "      <td>American Adjunct Lager</td>\n",
       "      <td>Defies comparison. Hating on this is like comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66881</th>\n",
       "      <td>American Adjunct Lager</td>\n",
       "      <td>Might be my least favorite AAL, mostly from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93688</th>\n",
       "      <td>Malt Liquor</td>\n",
       "      <td>Bottled in the 1970's era, and drank almost 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93689</th>\n",
       "      <td>Malt Liquor</td>\n",
       "      <td>Small pour at brewery. Looks lika glass of OJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93690</th>\n",
       "      <td>Malt Liquor</td>\n",
       "      <td>Small pour at brewery. Copper body with tiny h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93691</th>\n",
       "      <td>Malt Liquor</td>\n",
       "      <td>Four pack from brewery. Dark golden, patchy he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93692</th>\n",
       "      <td>Malt Liquor</td>\n",
       "      <td>Appearance is kind of a blue-green algae that’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Style  \\\n",
       "66877  American Adjunct Lager   \n",
       "66878  American Adjunct Lager   \n",
       "66879  American Adjunct Lager   \n",
       "66880  American Adjunct Lager   \n",
       "66881  American Adjunct Lager   \n",
       "...                       ...   \n",
       "93688             Malt Liquor   \n",
       "93689             Malt Liquor   \n",
       "93690             Malt Liquor   \n",
       "93691             Malt Liquor   \n",
       "93692             Malt Liquor   \n",
       "\n",
       "                                                  Review  \n",
       "66877  Sweet, clean, green apples, mild bitterness. S...  \n",
       "66878  Look...Clear pale yellow with a white carbonat...  \n",
       "66879  Look: Crystal clear yellow with an awesome-loo...  \n",
       "66880  Defies comparison. Hating on this is like comp...  \n",
       "66881  Might be my least favorite AAL, mostly from th...  \n",
       "...                                                  ...  \n",
       "93688  Bottled in the 1970's era, and drank almost 50...  \n",
       "93689  Small pour at brewery. Looks lika glass of OJ,...  \n",
       "93690  Small pour at brewery. Copper body with tiny h...  \n",
       "93691  Four pack from brewery. Dark golden, patchy he...  \n",
       "93692  Appearance is kind of a blue-green algae that’...  \n",
       "\n",
       "[26816 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T21:40:08.546609Z",
     "iopub.status.busy": "2023-03-21T21:40:08.545954Z",
     "iopub.status.idle": "2023-03-21T21:40:08.553275Z",
     "shell.execute_reply": "2023-03-21T21:40:08.552151Z",
     "shell.execute_reply.started": "2023-03-21T21:40:08.546573Z"
    },
    "id": "sgsQuYvakImj"
   },
   "outputs": [],
   "source": [
    "#df['Review'] = df.apply(lambda x: 'Group: {}. Review: {}'.format(x['Group'], x['Review']), axis=1)\n",
    "#df = df.drop('Group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XKD5DP_9lUW2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1T2nCFLymeVD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lables_list = []\n",
    "for gd in group_dfs:\n",
    "    labels = {}\n",
    "    for i, name in enumerate(gd['Style'].value_counts().index.tolist()):\n",
    "        labels[name] = i\n",
    "    lables_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tripel': 0,\n",
       " 'Belgian Pale Strong Ale': 1,\n",
       " 'Belgian Dark Strong Ale': 2,\n",
       " 'English Barleywine': 3,\n",
       " 'American Barleywine': 4,\n",
       " 'Scotch Ale / Wee Heavy': 5,\n",
       " 'Quadrupel (Quad)': 6,\n",
       " 'American Strong Ale': 7,\n",
       " 'Old Ale': 8,\n",
       " 'Imperial Red Ale': 9,\n",
       " 'English Strong Ale': 10,\n",
       " 'Wheatwine': 11}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(groups):\n",
    "    res[name] = {id: style for style, id in lables_list[i].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pale Lagers': {0: 'American Adjunct Lager',\n",
       "  1: 'German Pilsner',\n",
       "  2: 'European Pale Lager',\n",
       "  3: 'American Lager',\n",
       "  4: 'Helles',\n",
       "  5: 'Bohemian / Czech Pilsner',\n",
       "  6: 'Light Lager',\n",
       "  7: 'Kellerbier / Zwickelbier',\n",
       "  8: 'European / Dortmunder Export Lager',\n",
       "  9: 'Festbier / Wiesnbier',\n",
       "  10: 'European Strong Lager',\n",
       "  11: 'Malt Liquor',\n",
       "  12: 'India Pale Lager (IPL)',\n",
       "  13: 'Imperial Pilsner',\n",
       "  14: 'Czech Pale Lager'},\n",
       " 'Pale Ales': {0: 'English Pale Ale',\n",
       "  1: 'American Blonde Ale',\n",
       "  2: 'Saison',\n",
       "  3: 'American Pale Ale',\n",
       "  4: 'Kölsch',\n",
       "  5: 'American Amber / Red Ale',\n",
       "  6: 'Belgian Pale Ale',\n",
       "  7: 'English Bitter',\n",
       "  8: 'Extra Special / Strong Bitter (ESB)',\n",
       "  9: 'Irish Red Ale',\n",
       "  10: 'Belgian Blonde Ale',\n",
       "  11: 'Bière de Garde',\n",
       "  12: 'Grisette',\n",
       "  13: 'English Pale Mild Ale'},\n",
       " 'Strong Ales': {0: 'Tripel',\n",
       "  1: 'Belgian Pale Strong Ale',\n",
       "  2: 'Belgian Dark Strong Ale',\n",
       "  3: 'English Barleywine',\n",
       "  4: 'American Barleywine',\n",
       "  5: 'Scotch Ale / Wee Heavy',\n",
       "  6: 'Quadrupel (Quad)',\n",
       "  7: 'American Strong Ale',\n",
       "  8: 'Old Ale',\n",
       "  9: 'Imperial Red Ale',\n",
       "  10: 'English Strong Ale',\n",
       "  11: 'Wheatwine'},\n",
       " 'Stouts': {0: 'Russian Imperial Stout',\n",
       "  1: 'American Imperial Stout',\n",
       "  2: 'Sweet / Milk Stout',\n",
       "  3: 'American Stout',\n",
       "  4: 'Oatmeal Stout',\n",
       "  5: 'Irish Dry Stout',\n",
       "  6: 'Foreign / Export Stout',\n",
       "  7: 'English Stout'},\n",
       " 'India Pale Ales': {0: 'Imperial IPA',\n",
       "  1: 'American IPA',\n",
       "  2: 'New England IPA',\n",
       "  3: 'English IPA',\n",
       "  4: 'Black IPA',\n",
       "  5: 'Milkshake IPA',\n",
       "  6: 'Belgian IPA',\n",
       "  7: 'Brut IPA'},\n",
       " 'Wild/Sour Beers': {0: 'Wild Ale',\n",
       "  1: 'Gose',\n",
       "  2: 'Fruited Kettle Sour',\n",
       "  3: 'Berliner Weisse',\n",
       "  4: 'Fruit Lambic',\n",
       "  5: 'Flanders Red Ale',\n",
       "  6: 'Flanders Oud Bruin',\n",
       "  7: 'Brett Beer',\n",
       "  8: 'Gueuze',\n",
       "  9: 'Lambic',\n",
       "  10: 'Faro'},\n",
       " 'Specialty Beers': {0: 'Fruit and Field Beer',\n",
       "  1: 'Pumpkin Beer',\n",
       "  2: 'Low-Alcohol Beer',\n",
       "  3: 'Herb and Spice Beer',\n",
       "  4: 'Rye Beer',\n",
       "  5: 'Smoked Beer',\n",
       "  6: 'Chile Beer',\n",
       "  7: 'Japanese Rice Lager',\n",
       "  8: 'Gruit / Ancient Herbed Ale',\n",
       "  9: 'Kvass',\n",
       "  10: 'Happoshu',\n",
       "  11: 'Sahti'},\n",
       " 'Dark Lagers': {0: 'Märzen',\n",
       "  1: 'Munich Dunkel',\n",
       "  2: 'Schwarzbier',\n",
       "  3: 'Vienna Lager',\n",
       "  4: 'American Amber / Red Lager',\n",
       "  5: 'European Dark Lager',\n",
       "  6: 'Czech Dark Lager',\n",
       "  7: 'Rauchbier',\n",
       "  8: 'Czech Amber Lager'},\n",
       " 'Porters': {0: 'American Porter',\n",
       "  1: 'Imperial Porter',\n",
       "  2: 'Baltic Porter',\n",
       "  3: 'English Porter',\n",
       "  4: 'Robust Porter',\n",
       "  5: 'Smoked Porter'},\n",
       " 'Wheat Beers': {0: 'Hefeweizen',\n",
       "  1: 'Witbier',\n",
       "  2: 'American Pale Wheat Beer',\n",
       "  3: 'Dunkelweizen',\n",
       "  4: 'Kristallweizen',\n",
       "  5: 'Grodziskie',\n",
       "  6: 'American Dark Wheat Beer'},\n",
       " 'Brown Ales': {0: 'American Brown Ale',\n",
       "  1: 'English Brown Ale',\n",
       "  2: 'Altbier',\n",
       "  3: 'English Dark Mild Ale',\n",
       "  4: 'Belgian Dark Ale'},\n",
       " 'Bocks': {0: 'Doppelbock',\n",
       "  1: 'Bock',\n",
       "  2: 'Maibock',\n",
       "  3: 'Weizenbock',\n",
       "  4: 'Eisbock'},\n",
       " 'Dark Ales': {0: 'Winter Warmer',\n",
       "  1: 'Dubbel',\n",
       "  2: 'Scottish Ale',\n",
       "  3: 'Roggenbier'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2ofjs62fmrNn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_, labels_):\n",
    "        self.labels = [labels_[label] for label in df_['Style']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df_['Review']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T22:15:11.749598Z",
     "iopub.status.busy": "2023-03-21T22:15:11.748796Z",
     "iopub.status.idle": "2023-03-21T22:15:22.618129Z",
     "shell.execute_reply": "2023-03-21T22:15:22.616936Z",
     "shell.execute_reply.started": "2023-03-21T22:15:11.749538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=855bf7a0d608464fd6665585671b00ce0ad48d3a3599726c7fd197b273976930\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/9a/b1/2478e73a520d596fab614693f5cd1beef4ba3db737bed1ac7d\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21452 2682 2682\n",
      "18504 2313 2313\n",
      "16604 2076 2076\n",
      "13391 1674 1674\n",
      "11332 1417 1417\n",
      "10658 1333 1333\n",
      "9759 1220 1220\n",
      "9737 1218 1218\n",
      "7602 951 951\n",
      "6775 847 847\n",
      "5589 699 699\n",
      "4652 582 582\n",
      "3683 461 461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_splits = []\n",
    "for gd in group_dfs:\n",
    "    df_train, df_test = train_test_split(gd, train_size = 0.9, random_state=42, stratify = gd['Style'])\n",
    "    df_train, df_val = train_test_split(df_train, train_size = 0.88889, random_state=42, stratify = df_train['Style'])\n",
    "    df_splits.append((df_train, df_val, df_test))\n",
    "    print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jreKGxPOnzPE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BePq1fBgn9s0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs, labels):\n",
    "    print('Loading data into a dataset...')\n",
    "\n",
    "    train, val = Dataset(train_data, labels), Dataset(val_data, labels)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    print('Data loaded')\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "-9ETk5NKoLnm",
    "outputId": "94693fd2-5a3e-4c80-9a20-09e85d4cd05e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Pale Lagers\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10726/10726 [11:20<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.212                 | Train Accuracy:  0.210                 | Val Loss:  1.054                 | Val Accuracy:  0.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10726/10726 [11:37<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.987                 | Train Accuracy:  0.385                 | Val Loss:  0.921                 | Val Accuracy:  0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10726/10726 [12:04<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.854                 | Train Accuracy:  0.474                 | Val Loss:  0.862                 | Val Accuracy:  0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10726/10726 [12:03<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.749                 | Train Accuracy:  0.541                 | Val Loss:  0.841                 | Val Accuracy:  0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10726/10726 [11:26<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.648                 | Train Accuracy:  0.609                 | Val Loss:  0.838                 | Val Accuracy:  0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Pale Ales\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9252/9252 [09:48<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.154                 | Train Accuracy:  0.260                 | Val Loss:  0.924                 | Val Accuracy:  0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9252/9252 [09:50<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.810                 | Train Accuracy:  0.500                 | Val Loss:  0.770                 | Val Accuracy:  0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9252/9252 [10:11<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.682                 | Train Accuracy:  0.574                 | Val Loss:  0.720                 | Val Accuracy:  0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9252/9252 [09:47<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.597                 | Train Accuracy:  0.626                 | Val Loss:  0.715                 | Val Accuracy:  0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9252/9252 [09:47<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.517                 | Train Accuracy:  0.682                 | Val Loss:  0.723                 | Val Accuracy:  0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Strong Ales\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8302/8302 [08:47<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.081                 | Train Accuracy:  0.253                 | Val Loss:  0.888                 | Val Accuracy:  0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8302/8302 [08:50<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.800                 | Train Accuracy:  0.455                 | Val Loss:  0.768                 | Val Accuracy:  0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8302/8302 [09:15<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.694                 | Train Accuracy:  0.529                 | Val Loss:  0.719                 | Val Accuracy:  0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8302/8302 [09:04<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.613                 | Train Accuracy:  0.594                 | Val Loss:  0.722                 | Val Accuracy:  0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8302/8302 [08:47<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.530                 | Train Accuracy:  0.659                 | Val Loss:  0.702                 | Val Accuracy:  0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Stouts\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6696/6696 [07:05<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.964                 | Train Accuracy:  0.257                 | Val Loss:  0.863                 | Val Accuracy:  0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6696/6696 [07:04<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.813                 | Train Accuracy:  0.411                 | Val Loss:  0.793                 | Val Accuracy:  0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6696/6696 [07:04<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.727                 | Train Accuracy:  0.481                 | Val Loss:  0.769                 | Val Accuracy:  0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6696/6696 [07:04<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.658                 | Train Accuracy:  0.541                 | Val Loss:  0.765                 | Val Accuracy:  0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6696/6696 [07:04<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.575                 | Train Accuracy:  0.614                 | Val Loss:  0.774                 | Val Accuracy:  0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: India Pale Ales\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5666/5666 [06:01<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.954                 | Train Accuracy:  0.279                 | Val Loss:  0.819                 | Val Accuracy:  0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5666/5666 [06:14<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.667                 | Train Accuracy:  0.552                 | Val Loss:  0.551                 | Val Accuracy:  0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5666/5666 [05:59<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.492                 | Train Accuracy:  0.684                 | Val Loss:  0.499                 | Val Accuracy:  0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5666/5666 [06:04<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.397                 | Train Accuracy:  0.754                 | Val Loss:  0.483                 | Val Accuracy:  0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5666/5666 [06:19<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.315                 | Train Accuracy:  0.816                 | Val Loss:  0.484                 | Val Accuracy:  0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Wild/Sour Beers\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [05:38<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.071                 | Train Accuracy:  0.244                 | Val Loss:  0.920                 | Val Accuracy:  0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [05:43<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.802                 | Train Accuracy:  0.487                 | Val Loss:  0.749                 | Val Accuracy:  0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [05:56<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.649                 | Train Accuracy:  0.585                 | Val Loss:  0.657                 | Val Accuracy:  0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [05:55<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.542                 | Train Accuracy:  0.654                 | Val Loss:  0.616                 | Val Accuracy:  0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [05:56<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.451                 | Train Accuracy:  0.717                 | Val Loss:  0.617                 | Val Accuracy:  0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Specialty Beers\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [05:23<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.152                 | Train Accuracy:  0.242                 | Val Loss:  0.947                 | Val Accuracy:  0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [05:09<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.784                 | Train Accuracy:  0.529                 | Val Loss:  0.618                 | Val Accuracy:  0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [05:25<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.413                 | Train Accuracy:  0.797                 | Val Loss:  0.415                 | Val Accuracy:  0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [05:26<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.320                 | Train Accuracy:  0.835                 | Val Loss:  0.380                 | Val Accuracy:  0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [05:14<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.251                 | Train Accuracy:  0.873                 | Val Loss:  0.355                 | Val Accuracy:  0.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Dark Lagers\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [05:09<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.003                 | Train Accuracy:  0.280                 | Val Loss:  0.906                 | Val Accuracy:  0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [05:13<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.859                 | Train Accuracy:  0.423                 | Val Loss:  0.836                 | Val Accuracy:  0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [05:11<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.767                 | Train Accuracy:  0.490                 | Val Loss:  0.763                 | Val Accuracy:  0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [05:05<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.663                 | Train Accuracy:  0.571                 | Val Loss:  0.680                 | Val Accuracy:  0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [05:10<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.535                 | Train Accuracy:  0.649                 | Val Loss:  0.644                 | Val Accuracy:  0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Porters\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [04:03<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.856                 | Train Accuracy:  0.258                 | Val Loss:  0.776                 | Val Accuracy:  0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [04:02<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.724                 | Train Accuracy:  0.452                 | Val Loss:  0.715                 | Val Accuracy:  0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [04:01<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.645                 | Train Accuracy:  0.529                 | Val Loss:  0.700                 | Val Accuracy:  0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [04:02<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.578                 | Train Accuracy:  0.589                 | Val Loss:  0.692                 | Val Accuracy:  0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [04:01<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.502                 | Train Accuracy:  0.653                 | Val Loss:  0.697                 | Val Accuracy:  0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Wheat Beers\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3388/3388 [03:36<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.734                 | Train Accuracy:  0.456                 | Val Loss:  0.593                 | Val Accuracy:  0.590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3388/3388 [03:34<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.507                 | Train Accuracy:  0.678                 | Val Loss:  0.489                 | Val Accuracy:  0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3388/3388 [03:35<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.414                 | Train Accuracy:  0.739                 | Val Loss:  0.457                 | Val Accuracy:  0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3388/3388 [03:35<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.343                 | Train Accuracy:  0.792                 | Val Loss:  0.445                 | Val Accuracy:  0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3388/3388 [03:35<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.271                 | Train Accuracy:  0.847                 | Val Loss:  0.457                 | Val Accuracy:  0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Brown Ales\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2795/2795 [03:05<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.766                 | Train Accuracy:  0.327                 | Val Loss:  0.732                 | Val Accuracy:  0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2795/2795 [03:07<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.677                 | Train Accuracy:  0.433                 | Val Loss:  0.661                 | Val Accuracy:  0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2795/2795 [03:07<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.590                 | Train Accuracy:  0.515                 | Val Loss:  0.617                 | Val Accuracy:  0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2795/2795 [03:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.515                 | Train Accuracy:  0.587                 | Val Loss:  0.594                 | Val Accuracy:  0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2795/2795 [03:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.443                 | Train Accuracy:  0.658                 | Val Loss:  0.594                 | Val Accuracy:  0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Bocks\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:35<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.744                 | Train Accuracy:  0.335                 | Val Loss:  0.677                 | Val Accuracy:  0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:35<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.592                 | Train Accuracy:  0.522                 | Val Loss:  0.535                 | Val Accuracy:  0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:35<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.465                 | Train Accuracy:  0.669                 | Val Loss:  0.466                 | Val Accuracy:  0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:36<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.391                 | Train Accuracy:  0.727                 | Val Loss:  0.450                 | Val Accuracy:  0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:35<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.332                 | Train Accuracy:  0.775                 | Val Loss:  0.453                 | Val Accuracy:  0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for group: Dark Ales\n",
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1842/1842 [02:00<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.632                 | Train Accuracy:  0.448                 | Val Loss:  0.480                 | Val Accuracy:  0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1842/1842 [01:56<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.356                 | Train Accuracy:  0.750                 | Val Loss:  0.323                 | Val Accuracy:  0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1842/1842 [01:56<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.257                 | Train Accuracy:  0.814                 | Val Loss:  0.304                 | Val Accuracy:  0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1842/1842 [01:56<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.194                 | Train Accuracy:  0.865                 | Val Loss:  0.292                 | Val Accuracy:  0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1842/1842 [01:56<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.142                 | Train Accuracy:  0.920                 | Val Loss:  0.293                 | Val Accuracy:  0.807\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "models = []\n",
    "LR = 1e-6\n",
    "\n",
    "for ds in range(len(df_splits)):\n",
    "    model = BertClassifier(len(lables_list[ds]))\n",
    "    print(f'Training for group: {groups[ds]}')\n",
    "    train(model, df_splits[ds][0], df_splits[ds][1], LR, EPOCHS, lables_list[ds])\n",
    "    torch.save(model, f'{ds}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13ZKmNFVgtHY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    print('Loading data...')\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    print('Data loaded')\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            y_pred.append(output.argmax(dim=1))\n",
    "            y_true.append(test_label)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    return y_pred, y_true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-opItH68gtHZ",
    "outputId": "f7d4a4e2-eb6c-4faf-dc5e-633932445c53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for m in range(len(models)):\n",
    "    y_pred, y_true = evaluate(models[m], df_splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "load = torch.load('beert_model_simple.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C6CwWaHgtHa"
   },
   "source": [
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x.cpu() for x in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9hbg47agtHa"
   },
   "outputs": [],
   "source": [
    "classes = labels.keys()\n",
    "cf_matrix = confusion_matrix([x.cpu() for x in y_true], [y.cpu() for y in y_pred])\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vuSVPbqEXJvB"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "182f21a9fdb647efa7ae78602f07dbad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0b0a7e2c8db4a22922b8781b68f6cfc",
      "placeholder": "​",
      "style": "IPY_MODEL_af3e90442b2a4421bb01e8f8d963e378",
      "value": " 120/120 [2:08:46&lt;00:00, 63.08s/it]"
     }
    },
    "3a37fa36f455445cb30729f17e761a01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f09aea88b34ed6a19f89d7532d4370": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85fbb2e9dcda47d38b8ed81b3f79d8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95a133b3d0554bd2b53658c1a2306d8c",
       "IPY_MODEL_ff3306c20876460bae0659022586f2e6",
       "IPY_MODEL_182f21a9fdb647efa7ae78602f07dbad"
      ],
      "layout": "IPY_MODEL_75f09aea88b34ed6a19f89d7532d4370"
     }
    },
    "87bcdc616cdd4129a4d37eac6289ee97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95a133b3d0554bd2b53658c1a2306d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c72c373426af490cba4fc08767ebb91b",
      "placeholder": "​",
      "style": "IPY_MODEL_b376fccbe33f4a30a74a649de2d63fda",
      "value": "100%"
     }
    },
    "af3e90442b2a4421bb01e8f8d963e378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b376fccbe33f4a30a74a649de2d63fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c72c373426af490cba4fc08767ebb91b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b0a7e2c8db4a22922b8781b68f6cfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff3306c20876460bae0659022586f2e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a37fa36f455445cb30729f17e761a01",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87bcdc616cdd4129a4d37eac6289ee97",
      "value": 120
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
