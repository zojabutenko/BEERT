{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhimsXRgj3k0"
   },
   "source": [
    "# Flat, dropdown=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d4T2gADhW7C"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gI9VWEW4l19T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88TzLcQIhmWB"
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP0vNWTchq7X",
    "outputId": "d151225b-57d0-4038-e4ef-885512d7e007"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1bmr04biWB-NWRbRYbO3XBA33ltROqk47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"beer_df_large.csv\", sep=\"\\t\")\n",
    "df = df.drop(columns=['Name', 'Company', 'Region', 'ABV', 'Avg', 'Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sgsQuYvakImj"
   },
   "outputs": [],
   "source": [
    "df['Flat'] = df.apply(lambda x: '{}. {}'.format(x['Group'], x['Style']), axis=1)\n",
    "df = df.drop(columns=['Style', 'Group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "BIqPka3ylDuG",
    "outputId": "401f3531-da9d-42ca-ada4-ca3b7b542ac4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From a 12oz bottle into a cocktail glass.\\n\\nC...</td>\n",
       "      <td>Bocks. Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great relaxing beer. Very mellow, great taste-...</td>\n",
       "      <td>Bocks. Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Appearance: Clear, bright copper color. Frothy...</td>\n",
       "      <td>Bocks. Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a German staying for holidays in the US I c...</td>\n",
       "      <td>Bocks. Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would guess this is Shiner's #1 beer. It's p...</td>\n",
       "      <td>Bocks. Bock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174679</th>\n",
       "      <td>A really well done, well balanced sour with an...</td>\n",
       "      <td>Wild/Sour Beers. Wild Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174680</th>\n",
       "      <td>22oz bottle. Poured out a slightly hazy, brigh...</td>\n",
       "      <td>Wild/Sour Beers. Wild Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174681</th>\n",
       "      <td>There's lots of apricot in this beer, just a t...</td>\n",
       "      <td>Wild/Sour Beers. Wild Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174682</th>\n",
       "      <td>Poured from a 22oz bomber into my Drie de Font...</td>\n",
       "      <td>Wild/Sour Beers. Wild Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174683</th>\n",
       "      <td>Got this on sale at HEB for $7. Pretty good de...</td>\n",
       "      <td>Wild/Sour Beers. Wild Ale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  \\\n",
       "0       From a 12oz bottle into a cocktail glass.\\n\\nC...   \n",
       "1       Great relaxing beer. Very mellow, great taste-...   \n",
       "2       Appearance: Clear, bright copper color. Frothy...   \n",
       "3       As a German staying for holidays in the US I c...   \n",
       "4       I would guess this is Shiner's #1 beer. It's p...   \n",
       "...                                                   ...   \n",
       "174679  A really well done, well balanced sour with an...   \n",
       "174680  22oz bottle. Poured out a slightly hazy, brigh...   \n",
       "174681  There's lots of apricot in this beer, just a t...   \n",
       "174682  Poured from a 22oz bomber into my Drie de Font...   \n",
       "174683  Got this on sale at HEB for $7. Pretty good de...   \n",
       "\n",
       "                             Flat  \n",
       "0                     Bocks. Bock  \n",
       "1                     Bocks. Bock  \n",
       "2                     Bocks. Bock  \n",
       "3                     Bocks. Bock  \n",
       "4                     Bocks. Bock  \n",
       "...                           ...  \n",
       "174679  Wild/Sour Beers. Wild Ale  \n",
       "174680  Wild/Sour Beers. Wild Ale  \n",
       "174681  Wild/Sour Beers. Wild Ale  \n",
       "174682  Wild/Sour Beers. Wild Ale  \n",
       "174683  Wild/Sour Beers. Wild Ale  \n",
       "\n",
       "[174684 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XKD5DP_9lUW2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1T2nCFLymeVD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for i, name in enumerate(df['Flat'].value_counts().index.tolist()):\n",
    "    labels[name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pale Lagers. American Adjunct Lager': 0,\n",
       " 'Dark Lagers. Märzen': 1,\n",
       " 'Pale Lagers. German Pilsner': 2,\n",
       " 'Pale Lagers. European Pale Lager': 3,\n",
       " 'Pale Lagers. American Lager': 4,\n",
       " 'Pale Lagers. Helles': 5,\n",
       " 'Stouts. Russian Imperial Stout': 6,\n",
       " 'Stouts. American Imperial Stout': 7,\n",
       " 'Pale Lagers. Bohemian / Czech Pilsner': 8,\n",
       " 'Stouts. Sweet / Milk Stout': 9,\n",
       " 'India Pale Ales. Imperial IPA': 10,\n",
       " 'Strong Ales. Tripel': 11,\n",
       " 'Porters. American Porter': 12,\n",
       " 'Stouts. American Stout': 13,\n",
       " 'India Pale Ales. American IPA': 14,\n",
       " 'Pale Ales. English Pale Ale': 15,\n",
       " 'Specialty Beers. Fruit and Field Beer': 16,\n",
       " 'Stouts. Oatmeal Stout': 17,\n",
       " 'Wheat Beers. Hefeweizen': 18,\n",
       " 'Strong Ales. Belgian Pale Strong Ale': 19,\n",
       " 'Specialty Beers. Pumpkin Beer': 20,\n",
       " 'Strong Ales. Belgian Dark Strong Ale': 21,\n",
       " 'Brown Ales. American Brown Ale': 22,\n",
       " 'Pale Ales. American Blonde Ale': 23,\n",
       " 'India Pale Ales. New England IPA': 24,\n",
       " 'Wheat Beers. Witbier': 25,\n",
       " 'Pale Ales. Saison': 26,\n",
       " 'Pale Ales. American Pale Ale': 27,\n",
       " 'Pale Ales. Kölsch': 28,\n",
       " 'Strong Ales. English Barleywine': 29,\n",
       " 'Pale Ales. American Amber / Red Ale': 30,\n",
       " 'Wheat Beers. American Pale Wheat Beer': 31,\n",
       " 'Porters. Imperial Porter': 32,\n",
       " 'Wild/Sour Beers. Wild Ale': 33,\n",
       " 'Strong Ales. American Barleywine': 34,\n",
       " 'Wild/Sour Beers. Gose': 35,\n",
       " 'Strong Ales. Scotch Ale / Wee Heavy': 36,\n",
       " 'Wild/Sour Beers. Fruited Kettle Sour': 37,\n",
       " 'Pale Lagers. Light Lager': 38,\n",
       " 'Bocks. Doppelbock': 39,\n",
       " 'Dark Ales. Winter Warmer': 40,\n",
       " 'Wild/Sour Beers. Berliner Weisse': 41,\n",
       " 'Strong Ales. Quadrupel (Quad)': 42,\n",
       " 'Pale Lagers. Kellerbier / Zwickelbier': 43,\n",
       " 'Pale Ales. Belgian Pale Ale': 44,\n",
       " 'Porters. Baltic Porter': 45,\n",
       " 'Brown Ales. English Brown Ale': 46,\n",
       " 'Strong Ales. American Strong Ale': 47,\n",
       " 'India Pale Ales. English IPA': 48,\n",
       " 'Wild/Sour Beers. Fruit Lambic': 49,\n",
       " 'Dark Lagers. Munich Dunkel': 50,\n",
       " 'Specialty Beers. Low-Alcohol Beer': 51,\n",
       " 'India Pale Ales. Black IPA': 52,\n",
       " 'Pale Ales. English Bitter': 53,\n",
       " 'Dark Lagers. Schwarzbier': 54,\n",
       " 'Porters. English Porter': 55,\n",
       " 'Dark Lagers. Vienna Lager': 56,\n",
       " 'Bocks. Bock': 57,\n",
       " 'Pale Ales. Extra Special / Strong Bitter (ESB)': 58,\n",
       " 'Specialty Beers. Herb and Spice Beer': 59,\n",
       " 'India Pale Ales. Milkshake IPA': 60,\n",
       " 'Bocks. Maibock': 61,\n",
       " 'Dark Ales. Dubbel': 62,\n",
       " 'Pale Ales. Irish Red Ale': 63,\n",
       " 'Stouts. Irish Dry Stout': 64,\n",
       " 'Dark Lagers. American Amber / Red Lager': 65,\n",
       " 'Brown Ales. Altbier': 66,\n",
       " 'India Pale Ales. Belgian IPA': 67,\n",
       " 'Dark Ales. Scottish Ale': 68,\n",
       " 'Specialty Beers. Rye Beer': 69,\n",
       " 'Pale Lagers. European / Dortmunder Export Lager': 70,\n",
       " 'Pale Lagers. Festbier / Wiesnbier': 71,\n",
       " 'Stouts. Foreign / Export Stout': 72,\n",
       " 'Pale Lagers. European Strong Lager': 73,\n",
       " 'Pale Ales. Belgian Blonde Ale': 74,\n",
       " 'Dark Lagers. European Dark Lager': 75,\n",
       " 'Stouts. English Stout': 76,\n",
       " 'Pale Ales. Bière de Garde': 77,\n",
       " 'Pale Lagers. Malt Liquor': 78,\n",
       " 'Strong Ales. Old Ale': 79,\n",
       " 'Strong Ales. Imperial Red Ale': 80,\n",
       " 'Wild/Sour Beers. Flanders Red Ale': 81,\n",
       " 'Wild/Sour Beers. Flanders Oud Bruin': 82,\n",
       " 'Strong Ales. English Strong Ale': 83,\n",
       " 'Wheat Beers. Dunkelweizen': 84,\n",
       " 'Pale Lagers. India Pale Lager (IPL)': 85,\n",
       " 'Dark Lagers. Czech Dark Lager': 86,\n",
       " 'Brown Ales. English Dark Mild Ale': 87,\n",
       " 'Porters. Robust Porter': 88,\n",
       " 'Dark Lagers. Rauchbier': 89,\n",
       " 'Specialty Beers. Smoked Beer': 90,\n",
       " 'Specialty Beers. Chile Beer': 91,\n",
       " 'Brown Ales. Belgian Dark Ale': 92,\n",
       " 'Bocks. Weizenbock': 93,\n",
       " 'Wild/Sour Beers. Brett Beer': 94,\n",
       " 'Wild/Sour Beers. Gueuze': 95,\n",
       " 'Specialty Beers. Japanese Rice Lager': 96,\n",
       " 'India Pale Ales. Brut IPA': 97,\n",
       " 'Strong Ales. Wheatwine': 98,\n",
       " 'Pale Lagers. Imperial Pilsner': 99,\n",
       " 'Porters. Smoked Porter': 100,\n",
       " 'Pale Ales. Grisette': 101,\n",
       " 'Pale Lagers. Czech Pale Lager': 102,\n",
       " 'Specialty Beers. Gruit / Ancient Herbed Ale': 103,\n",
       " 'Wheat Beers. Kristallweizen': 104,\n",
       " 'Wild/Sour Beers. Lambic': 105,\n",
       " 'Pale Ales. English Pale Mild Ale': 106,\n",
       " 'Specialty Beers. Kvass': 107,\n",
       " 'Bocks. Eisbock': 108,\n",
       " 'Dark Lagers. Czech Amber Lager': 109,\n",
       " 'Dark Ales. Roggenbier': 110,\n",
       " 'Specialty Beers. Happoshu': 111,\n",
       " 'Wheat Beers. Grodziskie': 112,\n",
       " 'Wheat Beers. American Dark Wheat Beer': 113,\n",
       " 'Specialty Beers. Sahti': 114,\n",
       " 'Wild/Sour Beers. Faro': 115}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {id: style for style, id in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "2ofjs62fmrNn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['Flat']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['Review']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VsYY-Kpnsvh",
    "outputId": "b3574ec5-94f0-4862-c171-42347262c79f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139747 17468 17469\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jreKGxPOnzPE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 116)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "BePq1fBgn9s0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    print('Loading data into a dataset...')\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    print('Data loaded')\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "-9ETk5NKoLnm",
    "outputId": "94693fd2-5a3e-4c80-9a20-09e85d4cd05e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into a dataset...\n",
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69874/69874 [1:13:57<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  2.037                 | Train Accuracy:  0.119                 | Val Loss:  1.710                 | Val Accuracy:  0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69874/69874 [1:13:36<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  1.522                 | Train Accuracy:  0.289                 | Val Loss:  1.419                 | Val Accuracy:  0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69874/69874 [1:13:28<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  1.295                 | Train Accuracy:  0.374                 | Val Loss:  1.281                 | Val Accuracy:  0.375\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "myca65jTgtHY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'beert_flat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "13ZKmNFVgtHY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    print('Loading data...')\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    print('Data loaded')\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            y_pred.append(output.argmax(dim=1))\n",
    "            y_true.append(test_label)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-opItH68gtHZ",
    "outputId": "f7d4a4e2-eb6c-4faf-dc5e-633932445c53",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded\n",
      "Test Accuracy:  0.385\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('beert_flat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, labels_fli):\n",
    "    t = tokenizer(\n",
    "        text, \n",
    "        padding='max_length',\n",
    "        max_length = 512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        mask = t['attention_mask'].to(device)\n",
    "        input_id = t['input_ids'].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        pred = output.cpu().numpy()\n",
    "        idx = np.argmax(pred)\n",
    "        return labels_fli[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Specialty Beers. Fruit and Field Beer'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I would like to try some cherry beer', id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stouts. American Stout'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'Recommend me the darkest beer you can offer', id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pale Lagers. Light Lager'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I would like to try some light beer with low alcohol', id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stouts. Oatmeal Stout'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'oatmeal', id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C6CwWaHgtHa"
   },
   "source": [
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [np.argmax(x.cpu().numpy()) for x in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9hbg47agtHa"
   },
   "outputs": [],
   "source": [
    "classes = labels.keys()\n",
    "cf_matrix = confusion_matrix([x.cpu() for x in y_true], [y.cpu() for y in y_pred])\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vuSVPbqEXJvB"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "182f21a9fdb647efa7ae78602f07dbad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0b0a7e2c8db4a22922b8781b68f6cfc",
      "placeholder": "​",
      "style": "IPY_MODEL_af3e90442b2a4421bb01e8f8d963e378",
      "value": " 120/120 [2:08:46&lt;00:00, 63.08s/it]"
     }
    },
    "3a37fa36f455445cb30729f17e761a01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f09aea88b34ed6a19f89d7532d4370": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85fbb2e9dcda47d38b8ed81b3f79d8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95a133b3d0554bd2b53658c1a2306d8c",
       "IPY_MODEL_ff3306c20876460bae0659022586f2e6",
       "IPY_MODEL_182f21a9fdb647efa7ae78602f07dbad"
      ],
      "layout": "IPY_MODEL_75f09aea88b34ed6a19f89d7532d4370"
     }
    },
    "87bcdc616cdd4129a4d37eac6289ee97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95a133b3d0554bd2b53658c1a2306d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c72c373426af490cba4fc08767ebb91b",
      "placeholder": "​",
      "style": "IPY_MODEL_b376fccbe33f4a30a74a649de2d63fda",
      "value": "100%"
     }
    },
    "af3e90442b2a4421bb01e8f8d963e378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b376fccbe33f4a30a74a649de2d63fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c72c373426af490cba4fc08767ebb91b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b0a7e2c8db4a22922b8781b68f6cfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff3306c20876460bae0659022586f2e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a37fa36f455445cb30729f17e761a01",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87bcdc616cdd4129a4d37eac6289ee97",
      "value": 120
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
